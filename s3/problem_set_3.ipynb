{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.optimize import newton\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, it turns out the convergent profiles can actually be integrated analytically, with a small simplifying assumption.\n",
    "\n",
    "Suppose all the galaxies we're concerned with are approximately circular. Then the measure of integration for the intensity profile is just the differential area of a circular annulus $\\pi(r + dr)^2 - \\pi r^2 = 2\\pi r dr + O(dr^2)$\n",
    "\n",
    "We have\n",
    "\n",
    "$$ \\begin{align} \n",
    "    L_{deVaucouleur} &= 2\\pi \\int_0^\\infty  e^{-(r/R)^{1/4}}rdr \\\\[12pt]\n",
    "        &= 40320 \\pi R^{2}\n",
    "\\end{align}$$\n",
    "\n",
    "Proof is a straightforward (but incredibly long) exercise in iterative integration by parts that I left to Mathematica, but this does demonstrate convergence. We'll have to get $r_{1/2}$ numerically though, because even though Mathematica does give a formula for $L(r)$, it's too horrifying to be useful, and excruciating to typeset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336.72033367\n"
     ]
    }
   ],
   "source": [
    "R = 1\n",
    "\n",
    "L_tot = np.pi * 40320 * R*R\n",
    "# array of values of r to sample\n",
    "r = np.linspace(0,1e5,1e7)\n",
    "dr = r[1]-r[0]\n",
    "# L[i] will hold the total luminosity out to radius r[i]\n",
    "L = (2*np.pi)*np.cumsum(np.exp(-((r/R)**0.25))*r*dr)\n",
    "\n",
    "for i,f in enumerate(L/L_tot):\n",
    "    if 0.49 < f < 0.51:\n",
    "        print r[i]\n",
    "        break\n",
    "\n",
    "del L\n",
    "objcount = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently $r_{1/2}$ is at $3.3 \\times 10^3$ for $R=1$.\n",
    "\n",
    "For the spiral case,\n",
    "\n",
    "$$ \\begin{align} \n",
    "    \\int_0^r I_{spiral} dA &= 2\\pi \\int_0^r  e^{-(r/R)}rdr \\\\[12pt]\n",
    "        &= 2 \\pi R\\left(R-e^{-r/R}(R+r)\\right) \\\\[12pt]\n",
    "        &\\implies L_{spiral} = 2\\pi R^2\n",
    "\\end{align}$$\n",
    "\n",
    "So we find $r_{1/2}$ by requiring\n",
    "\n",
    "$$\n",
    "2 \\pi R\\left(R-e^{-r_{1/2}/R}(R+r_{1/2})\\right) - \\pi R^2 = 0\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$e^{-r_{1/2}/R}(R+r_{1/2}) = \\frac{R}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6783469900166605"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(r,R=1.0):\n",
    "    return np.exp(-r/R)*(R+r) - 0.5*R\n",
    "\n",
    "newton(f,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $r_{1/2}$ is $1.67 R$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum mass loss will occur if all of the galaxy's luminosity were due to mass loss. If such is the case,\n",
    "\n",
    "$$ L =-c^2\\frac{dM}{dt} $$\n",
    "\n",
    "The problem imposes though that $M/L = \\alpha$, for some constant $\\alpha$. This yields\n",
    "\n",
    "$$\\frac{dM}{dt}=-\\frac{1}{c^2\\alpha}M $$\n",
    "\n",
    "So we know\n",
    "\n",
    "$$ M = M_0 e^{-t/c^2\\alpha} $$\n",
    "\n",
    "If we need a numerical value for $M$, we do have to note that $\\alpha$ is not actually a unitless quantity. Assuming the problem's $\\alpha=10$ is valid in units where $c=3\\times10^8$, then at $t=10^{10}$ we have $M=(1-10^{-8})M_0$\n",
    "\n",
    "We can also estimate the fraction of hydrogen that has burned into helium if the galaxy were initially all hydrogen. We are given that hydrogen fusion causes an atom to lose $1-1/(1.007) = 0.7\\%$ of its mass, so only about one in 1.4 million hydrogen atoms have been burned by $10^{10}$ years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the definition of $\\Phi$, the galaxy density $N$ must be\n",
    "\n",
    "$$ N = \\int_0^\\infty \\Phi(L)dL = \\frac{\\Phi_*}{L_*}\\int_0^\\infty \\left(\\frac{L}{L_*}\\right)^{-\\alpha}e^{-L/L_*}dL$$\n",
    "\n",
    "The only issue is that $N$ is divergent for $\\alpha > 1$, which seems to be the case in this problem. However, for $\\alpha < 1$, this integral is easily recongnizable as $\\Phi_*\\Gamma(1-\\alpha)$.\n",
    "\n",
    "The luminosity per volume $\\mathcal{L}$ is\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\mathcal{L} &= \\int_0^\\infty \\Phi(L)LdL = \\Phi_*\\int_0^\\infty \\left(\\frac{L}{L_*}\\right)^{1-\\alpha}e^{-L/L_*}dL \\\\[12pt]\n",
    "&= \\Phi_* L_*\\Gamma(2-\\alpha)\n",
    "\\end{align}$$\n",
    "\n",
    "which converges for $\\alpha < 2$, and we finally get agreement with the problem statement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The 30 eV electron neutrino mass [V. A. Lubimov et al., Physics Letters B 94, 266 (1980)]\n",
    "\n",
    "In 1980, Lubimov et al. claimed a laboratory measurement of a finite electron neutrino mass based on the beta decay spectrum of tritium. This measurement, ostensibly of interest only to particle physicists, turned out to be extremely relevant to contemporary HDM theories in cosmology, which at the time were the leading dark matter theories. It turned out that a 30eV electron neutrino allowed HDM cosmologies to create flat universes in a manner consistent with inflation.\n",
    "\n",
    "Analysis of the Cfa galaxy redshift study in S. D. M. White, C. S. Frenk, and M. Davis, ApJL 274, L1 (1983) however showed that these 30eV electron neutrino models predicted a galaxy distribution inconsistent with observation, and at least as early as 1985, there were experimental particle physics papers claiming that Lubimov et al had grossly underestimated their instrumental systematic error.\n",
    "\n",
    "2) The BICEP-2 primordial gravitational wave signal [The BICEP2 Collaboration, Phys. Rev. Lett. 112, 241101, 2014]\n",
    "\n",
    "In 2014, the BICEP-2 collaboration claimed a conclusive detection of a curl component in its CMB polarization map that could only possibly be attributed to gravitational waves generated by cosmic inflation, apparently settling the major issues of cosmic inflation and the existence of gravitational simultaneously.\n",
    "\n",
    "The collaboration retracted the finding, citing higher than expected galactic dust foregrounds in A Joint Analysis of BICEP2/Keck Array and Planck Data, The BICEP2/Keck and Planck Collaborations, Phys. Rev. Lett. 114, 101301, 2015\n",
    "\n",
    "The primary failure in analysis on the part of BICEP-2 was to assume that blackbody radiation from galactic dust would carry homogenous polarization power spectral characteristics over the entire galaxy. BICEP-2 chose to observe a small patch of sky chosen to have a minimal density of galactic dust, and simply assumed the foreground power would decrease with the optical depth of the dst foreground. Even at the time, however, this dust assumption was under scrutiny, and BICEP-2 failed to test their foreground power assumptions with a follow up measurement from another instrument at another frequency. Doing so would have allowed BICEP-2 to fit out a blackbody component from their polarization maps, and conclude that the signal to noise on their claimed detection was actually significantly worse than published.\n",
    "\n",
    "3) Original value of the Hubble Constant [Mt. Wilson Contr., No. 324; Astroph. J., Chicago, Ill., 64, 1926 (321)]\n",
    "\n",
    "Although this paper is not a false discovery of a distance-recessional velocity correlation for very distant galaxies, it does rather overestimate the value of $H_0$. The problem arises from Hubble's determination of the distance to his redshift data set. Most of these distance errors result from subtleties in using Cepheids as standard candles. Coles and Lucchin claim that the overriding systematic error is in the difficulty of distinguishing Cepheids from W Virginis stars, which are not standard candles.\n",
    "\n",
    "The first paper identifying W Virginis variables is usually claimed to have been published in 1942 in a German publication, but my inability to read German prevents me from finding it. Given that 1942 is some time after 1929, it seems unlikely that Hubble or anyone else could have correctly estimated the measurement error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parallax in arcseconds is\n",
    "\n",
    "$$ p=648000\\pi b/d $$\n",
    "\n",
    "where b is the baseline, and d is the distance to the source. 1 AU / 100 Mpc is roughly $5 \\times 10^{-14}$, so the parallax to a 100 Mpc source will be 20 nanoarcseconds.\n",
    "\n",
    "Inverting this relation,\n",
    "\n",
    "$$ d = 648000\\pi b /p $$\n",
    "\n",
    "so the error $ \\delta d $ due to error in parallax measurement $ \\delta p$ will be\n",
    "\n",
    "$$ \\delta d = \\delta p \\left|\\frac{dd}{dp}\\right| = 648000\\pi b \\delta p / p^2$$\n",
    "\n",
    "so that requiring a 1 Mpc error means we need to have $p$ to within 40 picoarcseconds. If currently we can only get $\\delta p$ down to 0.1 microarseconds (2500 times the necessary value), we then need a baseline 2500 times longer. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
